{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a5b0df",
   "metadata": {},
   "source": [
    "### Definieren Sie den Pfad zu den Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_train='../01_Daten/pkl/df_all_15k-1.pkl'\n",
    "path_train='../01_Daten/pkl/df_all_15k-2.pkl'\n",
    "#path_train='../01_Daten/pkl/df_all_15k-3.pkl'\n",
    "path_val='../01_Daten/pkl/df_val_5k-2.pkl'\n",
    "#path_val='../01_Daten/pkl/df_val_5k-3.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cb910",
   "metadata": {},
   "source": [
    "### Modell wählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../01_Daten/model/original/bert-base-uncased'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f8950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../01_Daten/model/original/recobo-agriculture-bert-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d838533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../01_Daten/model/original/distilbert-distilbert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../01_Daten/model/original/microsoft-BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477d06c",
   "metadata": {},
   "source": [
    "### Model in cash Ordner dowlaoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df707d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 12 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dc6581a0ea40dfba3324d5164ecdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1250), Label(value='0 / 1250'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing training data...\n",
      "End...\n",
      "creating dataset...\n",
      "End...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb7d1e4453e439dbe0730c855bcb87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=417), Label(value='0 / 417'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing validation data...\n",
      "End...\n",
      "creating dataset...\n",
      "End...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 14:10:41,148] A new study created in memory with name: no-name-0be1205b-60f0-4519-a0e3-c500d3c61ff0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Hyperparameter-Suche...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 31:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>0.833254</td>\n",
       "      <td>0.693799</td>\n",
       "      <td>0.695667</td>\n",
       "      <td>0.698880</td>\n",
       "      <td>0.695667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.730700</td>\n",
       "      <td>0.787761</td>\n",
       "      <td>0.714255</td>\n",
       "      <td>0.715667</td>\n",
       "      <td>0.718697</td>\n",
       "      <td>0.715667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.709400</td>\n",
       "      <td>0.778446</td>\n",
       "      <td>0.715021</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.720542</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.775804</td>\n",
       "      <td>0.717644</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.723698</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.617300</td>\n",
       "      <td>0.767461</td>\n",
       "      <td>0.720605</td>\n",
       "      <td>0.722667</td>\n",
       "      <td>0.723590</td>\n",
       "      <td>0.722667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 14:42:00,876] Trial 0 finished with value: 2.8895287104885337 and parameters: {'learning_rate': 3.9553572993808816e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.0}. Best is trial 0 with value: 2.8895287104885337.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/4500 1:14:58, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.758600</td>\n",
       "      <td>0.792121</td>\n",
       "      <td>0.712696</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.713904</td>\n",
       "      <td>0.713667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.760473</td>\n",
       "      <td>0.721342</td>\n",
       "      <td>0.721333</td>\n",
       "      <td>0.725775</td>\n",
       "      <td>0.721333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.630500</td>\n",
       "      <td>0.767429</td>\n",
       "      <td>0.722722</td>\n",
       "      <td>0.723667</td>\n",
       "      <td>0.726681</td>\n",
       "      <td>0.723667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.779083</td>\n",
       "      <td>0.716453</td>\n",
       "      <td>0.716333</td>\n",
       "      <td>0.719324</td>\n",
       "      <td>0.716333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370900</td>\n",
       "      <td>0.849750</td>\n",
       "      <td>0.709908</td>\n",
       "      <td>0.711333</td>\n",
       "      <td>0.718559</td>\n",
       "      <td>0.711333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>0.863696</td>\n",
       "      <td>0.717986</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.721405</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.313400</td>\n",
       "      <td>0.951897</td>\n",
       "      <td>0.711200</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.715382</td>\n",
       "      <td>0.714000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.715469</td>\n",
       "      <td>0.718333</td>\n",
       "      <td>0.716699</td>\n",
       "      <td>0.718333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>1.049593</td>\n",
       "      <td>0.710044</td>\n",
       "      <td>0.713000</td>\n",
       "      <td>0.712807</td>\n",
       "      <td>0.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>1.092460</td>\n",
       "      <td>0.712015</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.713676</td>\n",
       "      <td>0.713667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>1.150061</td>\n",
       "      <td>0.707674</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.712665</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>1.140802</td>\n",
       "      <td>0.711766</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.713998</td>\n",
       "      <td>0.713667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 15:57:02,128] Trial 1 finished with value: 2.8530972115950197 and parameters: {'learning_rate': 7.526830416608007e-06, 'num_train_epochs': 12, 'per_device_train_batch_size': 32, 'weight_decay': 0.0}. Best is trial 0 with value: 2.8895287104885337.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 31:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.789905</td>\n",
       "      <td>0.711890</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.717540</td>\n",
       "      <td>0.710667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>0.745154</td>\n",
       "      <td>0.726032</td>\n",
       "      <td>0.724667</td>\n",
       "      <td>0.728948</td>\n",
       "      <td>0.724667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342900</td>\n",
       "      <td>0.880657</td>\n",
       "      <td>0.730004</td>\n",
       "      <td>0.729667</td>\n",
       "      <td>0.732711</td>\n",
       "      <td>0.729667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173100</td>\n",
       "      <td>1.067891</td>\n",
       "      <td>0.731789</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.731701</td>\n",
       "      <td>0.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.211124</td>\n",
       "      <td>0.730412</td>\n",
       "      <td>0.732333</td>\n",
       "      <td>0.729968</td>\n",
       "      <td>0.732333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 16:28:18,691] Trial 2 finished with value: 2.925046590635321 and parameters: {'learning_rate': 3.686226109211305e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.01}. Best is trial 2 with value: 2.925046590635321.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 32:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>0.917078</td>\n",
       "      <td>0.664680</td>\n",
       "      <td>0.669000</td>\n",
       "      <td>0.673749</td>\n",
       "      <td>0.669000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.827551</td>\n",
       "      <td>0.693237</td>\n",
       "      <td>0.695667</td>\n",
       "      <td>0.698215</td>\n",
       "      <td>0.695667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.684400</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.709109</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.713072</td>\n",
       "      <td>0.710667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>0.799246</td>\n",
       "      <td>0.712197</td>\n",
       "      <td>0.714333</td>\n",
       "      <td>0.716661</td>\n",
       "      <td>0.714333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.794129</td>\n",
       "      <td>0.712768</td>\n",
       "      <td>0.714667</td>\n",
       "      <td>0.716192</td>\n",
       "      <td>0.714667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 17:01:00,190] Trial 3 finished with value: 2.85829324371267 and parameters: {'learning_rate': 1.5463815489760432e-06, 'num_train_epochs': 5, 'per_device_train_batch_size': 16, 'weight_decay': 0.01}. Best is trial 2 with value: 2.925046590635321.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 1:18:18, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.780248</td>\n",
       "      <td>0.719673</td>\n",
       "      <td>0.719667</td>\n",
       "      <td>0.725614</td>\n",
       "      <td>0.719667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.735449</td>\n",
       "      <td>0.732251</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.732398</td>\n",
       "      <td>0.733000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.828805</td>\n",
       "      <td>0.722210</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.730112</td>\n",
       "      <td>0.722000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.943720</td>\n",
       "      <td>0.732415</td>\n",
       "      <td>0.730333</td>\n",
       "      <td>0.738080</td>\n",
       "      <td>0.730333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>1.262304</td>\n",
       "      <td>0.716430</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.721764</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>1.488834</td>\n",
       "      <td>0.727062</td>\n",
       "      <td>0.725667</td>\n",
       "      <td>0.730551</td>\n",
       "      <td>0.725667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>1.836028</td>\n",
       "      <td>0.696703</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.705055</td>\n",
       "      <td>0.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>1.914546</td>\n",
       "      <td>0.721055</td>\n",
       "      <td>0.722667</td>\n",
       "      <td>0.722515</td>\n",
       "      <td>0.722667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>2.087260</td>\n",
       "      <td>0.708658</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.713191</td>\n",
       "      <td>0.711000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>2.102918</td>\n",
       "      <td>0.715456</td>\n",
       "      <td>0.716333</td>\n",
       "      <td>0.718020</td>\n",
       "      <td>0.716333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.133932</td>\n",
       "      <td>0.715635</td>\n",
       "      <td>0.716333</td>\n",
       "      <td>0.717269</td>\n",
       "      <td>0.716333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.165598</td>\n",
       "      <td>0.712306</td>\n",
       "      <td>0.712667</td>\n",
       "      <td>0.714354</td>\n",
       "      <td>0.712667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:19:20,859] Trial 4 finished with value: 2.8519929911847544 and parameters: {'learning_rate': 1.2711673138235574e-05, 'num_train_epochs': 12, 'per_device_train_batch_size': 16, 'weight_decay': 0.0}. Best is trial 2 with value: 2.925046590635321.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 375/4500 06:12 < 1:08:34, 1.00 it/s, Epoch 1/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.792856</td>\n",
       "      <td>0.709629</td>\n",
       "      <td>0.708667</td>\n",
       "      <td>0.714061</td>\n",
       "      <td>0.708667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:25:34,545] Trial 5 pruned. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 375/4500 06:11 < 1:08:33, 1.00 it/s, Epoch 1/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.811602</td>\n",
       "      <td>0.702518</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>0.705534</td>\n",
       "      <td>0.704000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 18:31:48,151] Trial 6 pruned. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 31:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>0.788707</td>\n",
       "      <td>0.714840</td>\n",
       "      <td>0.713667</td>\n",
       "      <td>0.719428</td>\n",
       "      <td>0.713667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.608700</td>\n",
       "      <td>0.750889</td>\n",
       "      <td>0.730386</td>\n",
       "      <td>0.729333</td>\n",
       "      <td>0.732302</td>\n",
       "      <td>0.729333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.403800</td>\n",
       "      <td>0.844051</td>\n",
       "      <td>0.728205</td>\n",
       "      <td>0.728667</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.728667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229000</td>\n",
       "      <td>0.966097</td>\n",
       "      <td>0.724736</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.724244</td>\n",
       "      <td>0.726333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>1.061357</td>\n",
       "      <td>0.732160</td>\n",
       "      <td>0.733667</td>\n",
       "      <td>0.731730</td>\n",
       "      <td>0.733667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 19:03:04,779] Trial 7 finished with value: 2.9312236047395994 and parameters: {'learning_rate': 2.627351534620163e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.01}. Best is trial 7 with value: 2.9312236047395994.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  750/12000 06:29 < 1:37:34, 1.92 it/s, Epoch 1/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>0.674203</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>0.681622</td>\n",
       "      <td>0.677333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 19:09:35,191] Trial 8 pruned. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='12000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  750/12000 06:29 < 1:37:36, 1.92 it/s, Epoch 1/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.879821</td>\n",
       "      <td>0.673086</td>\n",
       "      <td>0.676333</td>\n",
       "      <td>0.680571</td>\n",
       "      <td>0.676333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-10 19:16:05,720] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hyperparameter-Suche abgeschlossen ---\n",
      "Beste Trial:\n",
      "  Wert (F1): BestRun(run_id='7', objective=2.9312236047395994, hyperparameters={'learning_rate': 2.627351534620163e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.01}, run_summary=None)\n",
      "\n",
      "------------------------------------------\n",
      "learning_rate: 2.627351534620163e-05\n",
      "num_train_epochs: 5\n",
      "per_device_train_batch_size : 32\n",
      "weight_decay: 0.01\n",
      "\n",
      "------------------END---------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training the final model with the best hyperparameters...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 32:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.770603</td>\n",
       "      <td>0.718035</td>\n",
       "      <td>0.717200</td>\n",
       "      <td>0.721889</td>\n",
       "      <td>0.717200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.743270</td>\n",
       "      <td>0.733946</td>\n",
       "      <td>0.733400</td>\n",
       "      <td>0.735157</td>\n",
       "      <td>0.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.824670</td>\n",
       "      <td>0.735380</td>\n",
       "      <td>0.736200</td>\n",
       "      <td>0.738224</td>\n",
       "      <td>0.736200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.948597</td>\n",
       "      <td>0.724583</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.725022</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>1.025523</td>\n",
       "      <td>0.729582</td>\n",
       "      <td>0.731800</td>\n",
       "      <td>0.729587</td>\n",
       "      <td>0.731800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the final model on the test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation Results:\n",
      "  eval_loss: 0.8441\n",
      "  eval_f1: 0.7292\n",
      "  eval_accuracy: 0.7297\n",
      "  eval_precision: 0.7324\n",
      "  eval_recall: 0.7297\n",
      "  eval_runtime: 29.4929\n",
      "  eval_samples_per_second: 101.7190\n",
      "  eval_steps_per_second: 12.7150\n",
      "  epoch: 5.0000\n",
      "\n",
      "Evaluating the final model on the validation set...\n",
      "\n",
      "Val Set Evaluation Results:\n",
      "  eval_loss: 0.8247\n",
      "  eval_f1: 0.7354\n",
      "  eval_accuracy: 0.7362\n",
      "  eval_precision: 0.7382\n",
      "  eval_recall: 0.7362\n",
      "  eval_runtime: 49.9135\n",
      "  eval_samples_per_second: 100.1730\n",
      "  eval_steps_per_second: 12.5220\n",
      "  epoch: 5.0000\n",
      "\n",
      " Saving the fine-tuned model and tokenizer...\n",
      "\n",
      "create predictions, to save in a df...\n",
      "--- 1. DF rdy ---\n",
      "Erstelle einen DataFrame nur mit den Vorhersagen, die vom Original abweichen (Validierungsset)...\n",
      "\n",
      "---  DFs rdy !!! ---\n",
      "--------------------------------------\n",
      "\n",
      "Anzahl der unterschiedlichen Vorhersagen im Validierungsset: 1319\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      " validation-set metrics (calculated from dfResults_pred):\n",
      "  Gewichteter F1-Score: 0.7354\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "Gesammelte Ergebnisse der Hyperparameter-Suche:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "runtimet: 341.10174187421796 min\n",
      "\n",
      " Script finished successfully!\n"
     ]
    }
   ],
   "source": [
    "boolHP = True # True: Hyperparameter-Suche, False: direktes Training mit festen Werten\n",
    "\n",
    "import time\n",
    "start_zeit = time.time()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer,  TrainingArguments, AutoConfig, AutoModelForSequenceClassification,DataCollatorWithPadding, TrainerCallback,TrainerState, TrainerControl\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Initialisiere pandarallel für parallele Verarbeitung\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definieren Sie das Cache-Verzeichnis\n",
    "cache_dir = '/media/ubuntu/5d2d9f9d-a02d-45ab-865f-3d789a0c70f0/download/'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dataset Klasse definieren\n",
    "class PublicationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "class HPSearchResultLoggerCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, metrics: dict, **kwargs):\n",
    "        \"\"\"\n",
    "        Wird nach jeder Evaluation aufgerufen, auch während der HP-Suche für jeden Trial.\n",
    "        \"\"\"\n",
    "        if state.is_hyper_param_search:\n",
    "            current_hyperparameters = state.trial_params if state.trial_params is not None else {}\n",
    "\n",
    "            log_entry = {}\n",
    "            # Füge alle Hyperparameter hinzu\n",
    "            log_entry.update(current_hyperparameters)\n",
    "\n",
    "            # Füge die gewünschten Metriken hinzu\n",
    "            log_entry['eval_dataset_type'] = 'train/HP'\n",
    "            log_entry['eval_loss'] = metrics.get(\"eval_loss\")\n",
    "            log_entry['eval_accuracy'] = metrics.get(\"eval_accuracy\")\n",
    "            log_entry['eval_f1'] = metrics.get(\"eval_f1\")\n",
    "            log_entry['eval_precision'] = metrics.get(\"precision\")\n",
    "            log_entry['eval_recall'] = metrics.get(\"eval_recall\")\n",
    "\n",
    "\n",
    "            hp_search_results_list.append(log_entry)\n",
    "            print(\"test:\\n \")\n",
    "            print(current_hyperparameters)\n",
    "            print(\"test end\\n \")\n",
    "            #print(f\"HP Search Trial Logged: {log_entry}\") # Optional: zum Debuggen\n",
    "\n",
    "def clean_text(text):\n",
    "    # HTML-Tags entfernen\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r\"[\\\",\\']\",\"\", text)  #  Anführungszeichen entfernen\n",
    "\n",
    "    # 1. Mehrfache Anführungszeichen durch ein normales ' ersetzen\n",
    "    text = re.sub(r\"'{2,}\", \"'\", text)\n",
    "\n",
    "    # 2. HTML-Tags entfernen [1, 2, 3]\n",
    "    # Sucht nach Mustern wie <tag>Inhalt</tag> und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # 3. URLs entfernen [1, 2, 3]\n",
    "    # Sucht nach gängigen URL-Mustern (http/https, www.) und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # 4. E-Mail-IDs entfernen [3]\n",
    "    # Sucht nach E-Mail-Mustern (Zeichenfolge@Zeichenfolge.Domain) und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "    # 5. Zusätzliche Leerzeichen normalisieren [1, 4]\n",
    "    # Teilt den Text nach Leerzeichen auf und fügt ihn mit einem einzigen Leerzeichen wieder zusammen.\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    text = re.sub(r\"[\\[,\\]]\",\"\", text)  # Mehrfache Leerzeichen zu einem reduzieren\n",
    "    \n",
    "\n",
    "    return text\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Berechnung des gewichteten F1-Scores\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    \n",
    "    # Optional: Berechnung weiterer Metriken\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0) # zero_division=0, um Warnungen zu vermeiden\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "def model_init(trial):\n",
    "    # Laden Sie die Konfiguration zuerst, um sie an LoRaBertForSequenceClassification zu übergeben\n",
    "    # num_labels muss global oder als Argument verfügbar sein\n",
    "    config = AutoConfig.from_pretrained(model_path, num_labels=num_labels, cache_dir=cache_dir)\n",
    "    \n",
    "\n",
    "    return BertForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        config=config,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "\n",
    "def time_now():\n",
    "    # Zeit funktion für den Dateinamen\n",
    "    current_dateTime = datetime.now()\n",
    "    time = str(current_dateTime.hour+2)+\"-\"+str(current_dateTime.minute)+\"_\"+str(current_dateTime.day) +\"-\"+ str(current_dateTime.month)+\"-\"+str(current_dateTime.year)\n",
    "    return str(time)\n",
    "\n",
    "def hp_space_optuna(trial):\n",
    "    # Hyperparameter-Suchraum für Optuna\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_categorical(\"num_train_epochs\",  [5, 12, 16]),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
    "        \n",
    "        \"weight_decay\": trial.suggest_categorical(\"weight_decay\",  [0.0, 0.01]),\n",
    "    }\n",
    "\n",
    "def prepare_val(df):\n",
    "    # Kombiniere Titel und Abstract\n",
    "    df['text'] = df['title'].astype(str) + \" - \" + df['abstract'].astype(str)\n",
    "    # Bereinigen Sie den Text\n",
    "    df[\"text\"] = df[\"text\"].parallel_apply(clean_text)\n",
    "    # encode the labels\n",
    "    df['label_encoded'] = le.fit_transform(df['class']).astype(int)\n",
    "\n",
    "    df = df.sample(frac=1)\n",
    "    X_val = df[\"text\"]\n",
    "    Y_val = df[\"label_encoded\"]  \n",
    "\n",
    "    print(\"Tokenizing validation data...\")\n",
    "    val_encodings = tokenizer(\n",
    "        list(X_val), truncation=True, padding=True, max_length=512)\n",
    "    print(\"End...\")\n",
    "    print(\"creating dataset...\")\n",
    "    ## Dataset erstellen\n",
    "    val_dataset = PublicationsDataset(val_encodings, Y_val.reset_index(drop=True))\n",
    "    print(\"End...\")\n",
    "    return val_dataset,df\n",
    "\n",
    "def prepare_test_train(df):\n",
    "    # Kombiniere Titel und Abstract\n",
    "    df['text'] = df['title'].astype(str) + \" - \" + df['abstract'].astype(str)\n",
    "\n",
    "    # Bereinigen Sie den Text\n",
    "    df[\"text\"] = df[\"text\"].parallel_apply(clean_text)\n",
    "\n",
    "    # encode the labels\n",
    "    df['label_encoded'] = le.fit_transform(df['class']).astype(int)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['text'], df['label_encoded'], test_size=0.2, random_state=42, stratify=df['label_encoded'])\n",
    "\n",
    "    print(\"Tokenizing training data...\")\n",
    "    train_encodings = tokenizer(\n",
    "        list(X_train), truncation=True, padding=True, max_length=512)\n",
    "    test_encodings = tokenizer(\n",
    "        list(X_test), truncation=True, padding=True, max_length=512)\n",
    "    print(\"End...\")\n",
    "    print(\"creating dataset...\")\n",
    "    ## Dataset erstellen\n",
    "    train_dataset = PublicationsDataset(train_encodings, y_train.reset_index(drop=True))\n",
    "    test_dataset = PublicationsDataset(test_encodings, y_test.reset_index(drop=True))\n",
    "    print(\"End...\")\n",
    "    return train_dataset,test_dataset,df\n",
    "\n",
    "\n",
    "\n",
    "# ---  Initialisierung ---\n",
    "model_name = model_path.split('/')[-1]\n",
    "\n",
    "#speicher Pfad für Logs und Modelle\n",
    "time_log_save = time_now()\n",
    "model_base_path = f\"../01_Daten/logs/{time_log_save}/{model_name}/\"\n",
    "model_log_path = model_base_path+\"logs/\"\n",
    "model_output_path = model_base_path+\"results/\"\n",
    "model_final_path = model_base_path+\"final_model/\"\n",
    "\n",
    "# LabelEncoder, tokenizer und  Data collator initialisieren\n",
    "le = LabelEncoder()\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path, cache_dir=cache_dir)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# --- Erstellen HP Trainer und args---\n",
    "train_dataset, test_dataset, dfBert_train = prepare_test_train(pd.read_pickle(path_train))\n",
    "val_dataset, dfBert_val = prepare_val(pd.read_pickle(path_val)) # Das ist jetzt das dedizierte Validierungsset\n",
    "\n",
    "if boolHP:\n",
    "\n",
    "    # num_labels auslesen für die Model-Initialisierung\n",
    "    num_labels = dfBert_train['label_encoded'].nunique()\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'{model_output_path}results_hp_search', \n",
    "        \n",
    "        learning_rate=1e-5,\n",
    "        num_train_epochs=1, \n",
    "        per_device_train_batch_size= 16,        \n",
    "        \n",
    "        # Feste Werte für die Suche:\n",
    "        logging_dir=f'{model_log_path}logs_hp_search',\n",
    "        logging_steps=10,\n",
    "        report_to=\"tensorboard\",\n",
    "        eval_strategy=\"epoch\", \n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=False,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "    # Trainer initialisieren (ohne ein festes Modell - model_init wird verwendet)\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # ---  Starten der Hyperparameter-Suche ---\n",
    "    print(\"Starte Hyperparameter-Suche...\")\n",
    "    # Starten der Hyperparameter-Suche\n",
    "    best_trial = trainer.hyperparameter_search(\n",
    "        direction=\"maximize\", # Maximiere den F1-Score\n",
    "        backend=\"optuna\",\n",
    "        n_trials=10, # Anzahl der Trials, die Optuna durchführen soll, je mehr Trials, desto länger dauert es, aber potenziell bessere Ergebnisse.\n",
    "        hp_space=hp_space_optuna,\n",
    "    )\n",
    "    print(\"\\n--- Hyperparameter-Suche abgeschlossen ---\")\n",
    "\n",
    "    print(\"Beste Trial:\")\n",
    "    print(f\"  Wert (F1): {best_trial}\") \n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"learning_rate: \"+str(best_trial.hyperparameters[\"learning_rate\"]))\n",
    "    print(\"num_train_epochs: \"+str(best_trial.hyperparameters[\"num_train_epochs\"]))\n",
    "    print(\"per_device_train_batch_size : \"+str(best_trial.hyperparameters[\"per_device_train_batch_size\"]))\n",
    "    print(\"weight_decay: \"+str(best_trial.hyperparameters[\"weight_decay\"]))\n",
    "    print(\"\\n------------------END---------------------\\n\\n\\n\")\n",
    "\n",
    "    # ---  Train with Best Hyperparameters ---\n",
    "    #update der TrainingArguments mit den besten Hyperparametern\n",
    "    best_hp = best_trial.hyperparameters\n",
    "\n",
    "\n",
    "    final_training_args = TrainingArguments(\n",
    "        output_dir=f\"{model_output_path}best_run\", \n",
    "        logging_dir=f\"{model_log_path}best_run\",\n",
    "        report_to=\"tensorboard\",\n",
    "        learning_rate=best_hp[\"learning_rate\"],\n",
    "        num_train_epochs=best_hp[\"num_train_epochs\"],\n",
    "        per_device_train_batch_size=best_hp[\"per_device_train_batch_size\"],\n",
    "        per_device_eval_batch_size=training_args.per_device_eval_batch_size, \n",
    "        weight_decay=best_hp.get(\"weight_decay\", training_args.weight_decay),\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=42\n",
    "    )\n",
    "else:\n",
    "    final_training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_output_path}best_run\", \n",
    "    logging_dir=f\"{model_log_path}best_run\",\n",
    "\n",
    "    learning_rate=2.7166361333742085e-05,\n",
    "    num_train_epochs= 3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay = 0.1,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit = 1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    seed=42\n",
    "    )\n",
    "\n",
    "# Initialisiere den Trainer mit den statischen Hyperparametern\n",
    "final_trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=final_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining the final model with the best hyperparameters...\")\n",
    "final_trainer.train()\n",
    "\n",
    "# ---  Evaluate the Final Model ---\n",
    "print(\"\\nEvaluating the final model on the test set...\")\n",
    "test_results = final_trainer.evaluate(test_dataset)\n",
    "print(\"\\nTest Set Evaluation Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating the final model on the validation set...\")\n",
    "val_results = final_trainer.evaluate(val_dataset)\n",
    "print(\"\\nVal Set Evaluation Results:\")\n",
    "for key, value in val_results.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if boolHP:\n",
    "    # # ---  Save the Final Model & Tokenizer ---\n",
    "    end_zeit = time.time()\n",
    "    laufzeit = end_zeit - start_zeit\n",
    "    print(\"\\n Saving the fine-tuned model and tokenizer...\")\n",
    "    final_trainer.save_model(f\"{model_final_path}model\")\n",
    "    tokenizer.save_pretrained(f\"{model_final_path}tokenizer/\")\n",
    "\n",
    "\n",
    "\n",
    "# # ---  Predict and to DF ---\n",
    "# --- Erstellen eines DataFrames mit Vorhersagen für das Validierungsset ---\n",
    "print(\"\\ncreate predictions, to save in a df...\")\n",
    "\n",
    "predictions_output_val = final_trainer.predict(val_dataset)\n",
    "predicted_scores_val = predictions_output_val.predictions\n",
    "predicted_labels_encoded_val = np.argmax(predicted_scores_val, axis=1)\n",
    "predicted_labels_named_val = le.inverse_transform(predicted_labels_encoded_val)\n",
    "\n",
    "dfResults_pred = pd.DataFrame()\n",
    "\n",
    "dfResults_pred['id_im_aktuellen_df'] = dfBert_val.index.values\n",
    "\n",
    "# Ursprüngliche Klasse (Text-Label) aus dfBert_val\n",
    "dfResults_pred['class_original'] = dfBert_val['class'].values\n",
    "\n",
    "# Ursprüngliche Klasse (numerisch kodiertes Label - Ground Truth) aus dfBert_val\n",
    "dfResults_pred['label_encoded_original'] = dfBert_val['label_encoded'].values\n",
    "\n",
    "# Vorhergesagte Klasse (numerisch kodiertes Label)\n",
    "dfResults_pred['prediction_encoded'] = predicted_labels_encoded_val\n",
    "\n",
    "# Vorhergesagte Klasse (Text-Label)\n",
    "dfResults_pred['prediction_named'] = predicted_labels_named_val\n",
    "\n",
    "# Optional: Fügen Sie den Text hinzu, der für die Vorhersage verwendet wurde\n",
    "dfResults_pred['text_input'] = dfBert_val['text'].values\n",
    "\n",
    "\n",
    "print(\"--- 1. DF rdy ---\")\n",
    "print(\"Erstelle einen DataFrame nur mit den Vorhersagen, die vom Original abweichen (Validierungsset)...\")\n",
    "# Filtere dfResults_pred, um nur Zeilen zu erhalten, bei denen das Original-Label und das vorhergesagte Label unterschiedlich sind.\n",
    "dfResults_pred_diff = dfResults_pred[dfResults_pred['label_encoded_original'] != dfResults_pred['prediction_encoded']]\n",
    "print(\"\\n---  DFs rdy !!! ---\")\n",
    "if dfResults_pred_diff.empty:\n",
    "    print(\"Keine Unterschiede zwischen Original- und Vorhersage-Labels im Validierungsset gefunden. Perfekte Vorhersage!\")\n",
    "else:\n",
    "    print(\"--------------------------------------\")\n",
    "    print(f\"\\nAnzahl der unterschiedlichen Vorhersagen im Validierungsset: {len(dfResults_pred_diff)}\")\n",
    "print(\"\\n-------------------------------------------\")\n",
    "\n",
    "# Wahre Labels und vorhergesagte Labels aus dem DataFrame extrahieren\n",
    "y_true_val = dfResults_pred['label_encoded_original']\n",
    "y_pred_val = dfResults_pred['prediction_encoded']\n",
    "\n",
    "print(\"\\n validation-set metrics (calculated from dfResults_pred):\")\n",
    "\n",
    "#Gewichteter F1-Score\n",
    "f1_val_weighted = f1_score(y_true_val, y_pred_val, average='weighted', zero_division=0)\n",
    "print(f\"  Gewichteter F1-Score: {f1_val_weighted:.4f}\")\n",
    "print(\"\\n------------------------------------------\")\n",
    "\n",
    "classification_report_val = classification_report(y_true_val, y_pred_val, target_names=le.classes_, zero_division=0)\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report_val)\n",
    "print(\"\\n------------------------------------------\")\n",
    "\n",
    "# Speichern der Ergebnisse\n",
    "dfResults_pred.to_pickle(f\"{model_base_path}dfResults_pred.pkl\")\n",
    "dfResults_pred_diff.to_pickle(f\"{model_base_path}dfResults_pred_diff({len(dfResults_pred_diff)}).pkl\")\n",
    "\n",
    "\n",
    "print(f\"runtimet: {laufzeit/60} min\")\n",
    "print(\"\\n Script finished successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6776c191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='7', objective=2.9312236047395994, hyperparameters={'learning_rate': 2.627351534620163e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'weight_decay': 0.01}, run_summary=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5be001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Beste Trial:\n",
      "\n",
      "learning_rate: 2.627351534620163e-05\n",
      "num_train_epochs: 5\n",
      "per_device_train_batch_size : 32\n",
      "weight_decay: 0.01\n",
      "\n",
      "------------------END---------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------\")\n",
    "print(\"Beste Trial:\\n\")\n",
    "\n",
    "print(\"learning_rate: \"+str(best_trial.hyperparameters[\"learning_rate\"]))\n",
    "print(\"num_train_epochs: \"+str(best_trial.hyperparameters[\"num_train_epochs\"]))\n",
    "print(\"per_device_train_batch_size : \"+str(best_trial.hyperparameters[\"per_device_train_batch_size\"]))\n",
    "print(\"weight_decay: \"+str(best_trial.hyperparameters[\"weight_decay\"]))\n",
    "#print(\"test: \"+str(best_trial.hyperparameters[\"warmup_ratio\"]))\n",
    "\n",
    "print(\"\\n------------------END---------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
