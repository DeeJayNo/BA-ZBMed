{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a7bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "cache_dir = '/media/ubuntu/5d2d9f9d-a02d-45ab-865f-3d789a0c70f0/download/'\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cae7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zum Beispiel:\n",
    "model_path=\"../01_Daten/logs/final/bert_multiclass_FT-15k/final_model/\"\n",
    "path_val=\"../01_Daten/pkl/df_val_5k-3.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Klasse definieren\n",
    "class PublicationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "def prepare_val(df):\n",
    "    # Kombiniere Titel und Abstract\n",
    "    df['text'] = df['title'].astype(str) + \" - \" + df['abstract'].astype(str)\n",
    "\n",
    "    # Bereinigen Sie den Text\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text).str.lower()\n",
    "    # encode the labels\n",
    "    df['label_encoded'] = le.fit_transform(df['class']).astype(int)\n",
    "    \n",
    "    df = df.sample(frac=1)\n",
    "    X_val = df[\"text\"]\n",
    "    Y_val = df[\"label_encoded\"]  \n",
    "\n",
    "\n",
    "\n",
    "    print(\"Tokenizing validation data...\")\n",
    "    val_encodings = loaded_tokenizer(\n",
    "        list(X_val), truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    tokenized_output = loaded_tokenizer(\n",
    "    df['text'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Typische maximale Länge für BERT-Modelle\n",
    "    )\n",
    "    df[\"text\"] =  tokenized_output\n",
    "    \n",
    "    print(\"End...\")\n",
    "    print(\"creating dataset...\")\n",
    "    ## Dataset erstellen\n",
    "    val_dataset = PublicationsDataset(val_encodings, Y_val.reset_index(drop=True))\n",
    "    print(\"End...\")\n",
    "    return val_dataset,df\n",
    "\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "    # HTML-Tags entfernen\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r\"[\\\",\\']\",\"\", text)  #  Anführungszeichen entfernen\n",
    "\n",
    "    # 1. Mehrfache Anführungszeichen durch ein normales ' ersetzen\n",
    "    text = re.sub(r\"'{2,}\", \"'\", text)\n",
    "\n",
    "    # 2. HTML-Tags entfernen [1, 2, 3]\n",
    "    # Sucht nach Mustern wie <tag>Inhalt</tag> und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # 3. URLs entfernen [1, 2, 3]\n",
    "    # Sucht nach gängigen URL-Mustern (http/https, www.) und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # 4. E-Mail-IDs entfernen [3]\n",
    "    # Sucht nach E-Mail-Mustern (Zeichenfolge@Zeichenfolge.Domain) und ersetzt sie durch einen leeren String.\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "\n",
    "    # 5. Zusätzliche Leerzeichen normalisieren [1, 4]\n",
    "    # Teilt den Text nach Leerzeichen auf und fügt ihn mit einem einzigen Leerzeichen wieder zusammen.\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    text = re.sub(r\"[\\[,\\]]\",\"\", text)  # Mehrfache Leerzeichen zu einem reduzieren\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf937c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing validation data...\n",
      "End...\n",
      "creating dataset...\n",
      "End...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path=\"../01_Daten/logs/final/bert_multiclass_FT-15k/final_model/\"\n",
    "loaded_model_path=model_path+\"model\"\n",
    "loaded_tokenizer_path=model_path+\"tokenizer\"\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(loaded_model_path,cache_dir=cache_dir)\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(loaded_tokenizer_path, cache_dir=cache_dir)\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=loaded_model, tokenizer=loaded_tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Load Validation DF\n",
    "val_dataset, dfBert_val = prepare_val(pd.read_pickle(path_val))\n",
    "\n",
    "# Klassifikation auf jede Zeile anwenden\n",
    "dfBert_val['predictions_encoded'] = dfBert_val['text'].apply(lambda x:  classifier(x, truncation=True, max_length=512)[0]['label'])\n",
    "dfBert_val['predictions_encoded'] = dfBert_val['predictions_encoded'].apply(lambda x: int(x[6:]))\n",
    "dfBert_val['predicted_labels_named'] = dfBert_val['predictions_encoded'].apply(lambda x: le.inverse_transform([x])[0])\n",
    "\n",
    "# Wahre Labels und vorhergesagte Labels aus dem DataFrame extrahieren\n",
    "y_true_val = dfBert_val['label_encoded']\n",
    "y_pred_val = dfBert_val['predictions_encoded']\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03417eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"------------------------------------------\")\n",
    "print(\"\\nvalidation-set metrics (calculated from dfResults_pred):\")\n",
    "#F1-Score\n",
    "f1_val_weighted = f1_score(y_true_val, y_pred_val, average='weighted', zero_division=0)\n",
    "print(f\"F1-Score: {f1_val_weighted:.4f}\")\n",
    "print(\"\\n------------------------------------------\")\n",
    "\n",
    "\n",
    "dfResults_pred_diff = dfBert_val[dfBert_val['label_encoded'] != dfBert_val['predictions_encoded']]\n",
    "if dfResults_pred_diff.empty:\n",
    "    print(\"\\nKeine Unterschiede zwischen Original- und Vorhersage-Labels im Validierungsset gefunden. Perfekte Vorhersage!\")\n",
    "else:\n",
    "    print(f\"\\nAnzahl der unterschiedlichen Vorhersagen im Validierungsset: {len(dfResults_pred_diff)}\")\n",
    "print(\"\\n-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05f30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTRAL\n",
    "base_path = \"../01_Daten/logs/final/mistral_classifier_final_v2\" # <--- BITTE ANPASSEN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf045c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory exists at: ../01_Daten/logs/final/distilbert-base-multilingual-cased\n"
     ]
    }
   ],
   "source": [
    "#path checker\n",
    "import os\n",
    "                \n",
    "#model_path = \"../01_Daten/logs/FULL_bert_multiclass_FT-15k/bert_multiclass_FT-15k/final_model/model\"\n",
    "if os.path.exists(base_path):\n",
    "    print(f\"Model directory exists at: {base_path}\")\n",
    "else:\n",
    "    print(f\"Model directory not found at: {base_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbd80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "base_path = \"../01_Daten/logs/final/bert_multiclass_FT-15k\" # <--- BITTE ANPASSEN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3305c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert\n",
    "base_path = \"../01_Daten/logs/final/distilbert-base-multilingual-cased\" # <--- BITTE ANPASSEN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a2eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pubmed\n",
    "base_path = \"../01_Daten/logs/final/PubMedBert_multiclass_FT-15k\" # <--- BITTE ANPASSEN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340074be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agriculture\n",
    "base_path = \"../01_Daten/logs/final/agriculture-bert-uncased\" # <--- BITTE ANPASSEN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058ea1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Modell von: ../01_Daten/logs/final/agriculture-bert-uncased/final_model/model\n",
      "Modell und Tokenizer erfolgreich geladen.\n",
      "Lade Trainingsdaten von '../01_Daten/pkl/df_all_15k-2.pkl', um den LabelEncoder zu fitten...\n",
      "LabelEncoder wurde mit den Trainingsdaten gefittet und ist bereit.\n",
      "Lade und bereite Validierungsdaten von '../01_Daten/pkl/df_all_15k.pkl' vor...\n",
      "Kombiniere und bereinige Textspalten...\n",
      "Textcleaning startet...\n",
      "ohne lower...\n",
      "Tokenisiere Daten für die Vorhersage...\n",
      "Datensatz für die Vorhersage bereit.\n",
      "\n",
      "Starte die Vorhersage auf dem Validierungsdatensatz...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vorhersage abgeschlossen.\n",
      "\n",
      "Verarbeite die Vorhersage-Ergebnisse...\n",
      "\n",
      "--- Metriken der Vorhersage agriculture-bert-uncased ---\n",
      "Gewichteter F1-Score: 0.7301\n",
      "\n",
      "Detaillierter Klassifikations-Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Ernährung       0.74      0.72      0.73      3000\n",
      "      Landwirtschaft       0.67      0.82      0.73      3000\n",
      "             Medizin       0.76      0.71      0.74      3000\n",
      "                Rest       0.68      0.61      0.64      3000\n",
      "Umweltwissenschaften       0.82      0.79      0.81      3000\n",
      "\n",
      "            accuracy                           0.73     15000\n",
      "           macro avg       0.73      0.73      0.73     15000\n",
      "        weighted avg       0.73      0.73      0.73     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, classification_report # <-- Hinzugefügt\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "\n",
    "model_name_print = base_path.split(\"/\")\n",
    "model_name_print = model_name_print[4] \n",
    "\n",
    "# ============== KONFIGURATION & HILFSFUNKTIONEN ==============\n",
    "class PublicationsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Eigene Dataset-Klasse für PyTorch.\"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Bereinigt einen Text von HTML-Tags und anderen Störungen.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    text = re.sub(r\"[\\\",\\']\", \"\", text)\n",
    "    text = re.sub(r\"'{2,}\", \"'\", text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    text = re.sub(r\"[\\[,\\]]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def prepare_prediction_data(df: pd.DataFrame, tokenizer, le: LabelEncoder) -> tuple[PublicationsDataset, pd.DataFrame]:\n",
    "    df = df.sample(frac=1)\n",
    "    \"\"\"Bereitet einen DataFrame für die Vorhersage vor.\"\"\"\n",
    "    print(\"Kombiniere und bereinige Textspalten...\")\n",
    "    df['text'] = df['title'].astype(str) + \" - \" + df['abstract'].astype(str)\n",
    "    df['class'] = df['class'].str.replace(r'ErnÃ¤hrung', 'Ernährung', regex=True)\n",
    "    print(\"Textcleaning startet...\")\n",
    "    if \"cased\" in base_path:\n",
    "        print(\"ohne lower...\")\n",
    "        df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "    else:\n",
    "        df[\"text\"] = df[\"text\"].apply(clean_text).str.lower()\n",
    "    df['label_encoded'] = le.transform(df['class']).astype(int)\n",
    "    \n",
    "\n",
    "\n",
    "    X_val = df[\"text\"].tolist()\n",
    "    Y_val = df[\"label_encoded\"]\n",
    "\n",
    "    print(\"Tokenisiere Daten für die Vorhersage...\")\n",
    "    encodings = tokenizer(X_val, truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    dataset = PublicationsDataset(encodings, Y_val.reset_index(drop=True))\n",
    "    print(\"Datensatz für die Vorhersage bereit.\")\n",
    "    return dataset, df\n",
    "\n",
    "# ============== HAUPTSKRIPT ZUM AUSFÜHREN ==============\n",
    "\n",
    "if \"mistral\" in base_path:\n",
    "    model_path = os.path.join(base_path, \"final_model\")\n",
    "    tokenizer_path = os.path.join(base_path, \"final_model\")\n",
    "else:\n",
    "    model_path = os.path.join(base_path, \"final_model/model\")\n",
    "    tokenizer_path = os.path.join(base_path, \"final_model/tokenizer/\")\n",
    "\n",
    "path_train = '../01_Daten/pkl/df_all_15k-2.pkl'\n",
    "path_val = '../01_Daten/pkl/df_all_15k.pkl'\n",
    "\n",
    "# --- Schritt 1: Modell und Tokenizer laden ---\n",
    "print(f\"Lade Modell von: {model_path}\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Modell-Verzeichnis nicht gefunden: {model_path}. Bitte den `base_path` prüfen.\")\n",
    "    \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"Modell und Tokenizer erfolgreich geladen.\")\n",
    "\n",
    "# --- Schritt 2: LabelEncoder mit Trainingsdaten wiederherstellen ---\n",
    "print(f\"Lade Trainingsdaten von '{path_train}', um den LabelEncoder zu fitten...\")\n",
    "df_train = pd.read_pickle(path_train)\n",
    "df_train['class'] = df_train['class'].str.replace(r'ErnÃ¤hrung', 'Ernährung', regex=True)\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['class'])\n",
    "print(\"LabelEncoder wurde mit den Trainingsdaten gefittet und ist bereit.\")\n",
    "\n",
    "# --- Schritt 3: Validierungs-Daten vorbereiten ---\n",
    "print(f\"Lade und bereite Validierungsdaten von '{path_val}' vor...\")\n",
    "df_val_original = pd.read_pickle(path_val)\n",
    "val_dataset, dfBert_val = prepare_prediction_data(df_val_original, tokenizer, le)\n",
    "\n",
    "# --- Schritt 4: Vorhersage durchführen ---\n",
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./prediction_temp\",\n",
    "    per_device_eval_batch_size=64,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "predictor = Trainer(\n",
    "    model=model,\n",
    "    args=prediction_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "print(\"\\nStarte die Vorhersage auf dem Validierungsdatensatz...\")\n",
    "predictions_output = predictor.predict(val_dataset)\n",
    "print(\"Vorhersage abgeschlossen.\")\n",
    "\n",
    "# --- Schritt 5: Ergebnisse verarbeiten ---\n",
    "print(\"\\nVerarbeite die Vorhersage-Ergebnisse...\")\n",
    "predicted_scores = predictions_output.predictions\n",
    "predicted_labels_encoded = np.argmax(predicted_scores, axis=1)\n",
    "predicted_labels_named = le.inverse_transform(predicted_labels_encoded)\n",
    "\n",
    "dfResults_pred = pd.DataFrame({\n",
    "    'id_im_aktuellen_df': dfBert_val.index.values,\n",
    "    'class_original': dfBert_val['class'].values,\n",
    "    'label_encoded_original': dfBert_val['label_encoded'].values,\n",
    "    'prediction_encoded': predicted_labels_encoded,\n",
    "    'prediction_named': predicted_labels_named,\n",
    "    'text_input': dfBert_val['text'].values\n",
    "})\n",
    "#print(\"--- Ergebnis-DataFrame (die ersten 5 Zeilen): ---\")\n",
    "#print(dfResults_pred.head())\n",
    "\n",
    "# --- Schritt 6: Metriken berechnen und ausgeben ---\n",
    "print(f\"\\n--- Metriken der Vorhersage {model_name_print} ---\")\n",
    "y_true = dfResults_pred['label_encoded_original']\n",
    "y_pred = dfResults_pred['prediction_encoded']\n",
    "\n",
    "# Gewichteten F1-Score berechnen\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "print(f\"Gewichteter F1-Score: {f1_weighted:.4f}\")\n",
    "\n",
    "# Detaillierten Report ausgeben\n",
    "print(\"\\nDetaillierter Klassifikations-Report:\")\n",
    "# `le.classes_` liefert die Namen der Klassen in der richtigen Reihenfolge\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "print(report)\n",
    "\n",
    "# --- Schritt 7: Ergebnisse speichern ---\n",
    "#output_file_path = os.path.join(base_path, \"rerun_predictions_with_metrics.pkl\")\n",
    "#dfResults_pred.to_pickle(output_file_path)\n",
    "#print(f\"\\nVollständige Ergebnisse wurden in '{output_file_path}' gespeichert.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b4c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14111601",
   "metadata": {},
   "source": [
    "--- Metriken der Vorhersage bert_multiclass_FT-15k ---\n",
    "<br>\n",
    "Gewichteter F1-Score: 0.7189\n",
    "\n",
    "Detaillierter Klassifikations-Report:\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "           Ernährung       0.72      0.70      0.71      3000\n",
    "      Landwirtschaft       0.66      0.78      0.72      3000\n",
    "             Medizin       0.74      0.72      0.73      3000\n",
    "                Rest       0.66      0.62      0.64      3000\n",
    "Umweltwissenschaften       0.83      0.77      0.80      3000\n",
    "\n",
    "            accuracy                           0.72     15000\n",
    "           macro avg       0.72      0.72      0.72     15000\n",
    "        weighted avg       0.72      0.72      0.72     15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6aa41e",
   "metadata": {},
   "source": [
    "--- Metriken der Vorhersage distilbert-base-multilingual-cased ---\n",
    "<br>\n",
    "Gewichteter F1-Score: 0.7123\n",
    "\n",
    "Detaillierter Klassifikations-Report:\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "           Ernährung       0.68      0.71      0.70      3000\n",
    "      Landwirtschaft       0.73      0.70      0.71      3000\n",
    "             Medizin       0.76      0.67      0.71      3000\n",
    "                Rest       0.65      0.64      0.64      3000\n",
    "Umweltwissenschaften       0.76      0.85      0.80      3000\n",
    "\n",
    "            accuracy                           0.71     15000\n",
    "           macro avg       0.71      0.71      0.71     15000\n",
    "        weighted avg       0.71      0.71      0.71     15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef973335",
   "metadata": {},
   "source": [
    "--- Metriken der Vorhersage PubMedBert_multiclass_FT-15k ---\n",
    "<br>\n",
    "Gewichteter F1-Score: 0.7214\n",
    "\n",
    "Detaillierter Klassifikations-Report:\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "           Ernährung       0.66      0.79      0.72      3000\n",
    "      Landwirtschaft       0.71      0.75      0.73      3000\n",
    "             Medizin       0.77      0.68      0.72      3000\n",
    "                Rest       0.67      0.58      0.62      3000\n",
    "Umweltwissenschaften       0.80      0.82      0.81      3000\n",
    "\n",
    "            accuracy                           0.72     15000\n",
    "           macro avg       0.73      0.72      0.72     15000\n",
    "        weighted avg       0.73      0.72      0.72     15000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48881739",
   "metadata": {},
   "source": [
    "--- Metriken der Vorhersage agriculture-bert-uncased ---\n",
    "Gewichteter F1-Score: 0.7301\n",
    "\n",
    "Detaillierter Klassifikations-Report:\n",
    "                      precision    recall  f1-score   support\n",
    "\n",
    "           Ernährung       0.74      0.72      0.73      3000\n",
    "      Landwirtschaft       0.67      0.82      0.73      3000\n",
    "             Medizin       0.76      0.71      0.74      3000\n",
    "                Rest       0.68      0.61      0.64      3000\n",
    "Umweltwissenschaften       0.82      0.79      0.81      3000\n",
    "\n",
    "            accuracy                           0.73     15000\n",
    "           macro avg       0.73      0.73      0.73     15000\n",
    "        weighted avg       0.73      0.73      0.73     15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63a81b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
